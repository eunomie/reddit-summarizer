# Use Docker Model Runner
OPENAI_BASE_URL=http://model-runner.docker.internal/engines/llama.cpp/v1/

# Disable streaming when using tools, for llama.cpp and Docker Model Runner
OPENAI_DISABLE_STREAMING=true

# Define the default model to use
OPENAI_MODEL=ai/llama3.2:1B-Q8_0

