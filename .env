# Use Docker Model Runner
OPENAI_BASE_URL=http://model-runner.docker.internal/engines/llama.cpp/v1/

# Disable streaming when using tools, for llama.cpp and Docker Model Runner
OPENAI_DISABLE_STREAMING=true

# Define the default model to use
OPENAI_MODEL=eunomie/qwen2.5-coder-3b-instruct:q8_0
